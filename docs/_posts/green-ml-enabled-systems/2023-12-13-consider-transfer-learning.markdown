---
layout: tactic
title: Consider Transfer Learning
tags:
  - machine-learning
  - model-optimization
t-sort: Awesome Tactic
t-type: Architectural Tactic
categories: green-ml-enabled-systems
t-description: Transfer learning means using knowledge gained from one task (a pre-trained model) and applying it to another similar task. This is feasible only if there is an existing pre-trained model available for use. The absence of or reduction in the model training effort in case of fine-tuning results in savings in energy consumption.
t-participant: Data Scientist
t-artifact: Machine Learning Algorithm
t-context: Machine Learning
t-feature: Neural Networks
t-intent: Improve energy efficiency by using transfer learning with pre-trained models whenever feasible
t-targetQA: Energy Efficiency
t-relatedQA: <Unavailable>
t-measuredimpact: <Unavailable>
t-source: 'Nitthilan Kanappan Jayakodi, Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. 2020. Design and Optimization Of Energy-Accuracy Tradeoff Networks For Mobile Platforms Via Pretrained Deep Models. ACM Transactions on Embedded Computing Systems (TECS) 19, 1 (2020), 1–24. [DOI](https://doi.org/10.1145/3366636); Shriram Shanbhag, Sridhar Chimalakonda, Vibhu Saujanya Sharma, and Vikrant Kaulgud. 2022. Towards a Catalog of Energy Patterns in Deep Learning Development. In Proceedings of the International Conference on Evaluation and Assessment in Software Engineering 2022. 150–159. [DOI](https://doi.org/10.1145/3530019.3530035)'
t-source-doi: <Unavailable>
t-diagram: consider-transfer-learning.png
t-intentmeasure: <Unavailable>
t-countermeasure: <Unavailable>
---
