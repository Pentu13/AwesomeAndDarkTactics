{
  "layout": "tactic",
  "title": "Reduce Number of Data Features",
  "tags": [
    "machine-learning",
    "data-centric",
    "measured"
  ],
  "t-sort": "Awesome Tactic",
  "t-type": "Architectural Tactic",
  "categories": "green-ml-enabled-systems",
  "t-description": "A large number of data features can lead to high computing power requirements for training and inference. Typi- cally, machine learning scenarios involve a huge number of features or variables that describe the input data. However, not all these features are necessary for the model to make accurate predictions. Therefore, reducing these data features can lead to improved energy efficiency while still maintaining accuracy. Reducing the number of input features can be achieved by selecting only a subset the available data features.",
  "t-participant": "Data Scientist",
  "t-artifact": "Data",
  "t-context": "Machine Learning",
  "t-feature": "<Unavailable>",
  "t-intent": "Enhance energy efficiency by reducing the number of data features by choosing only a subset of all the available features",
  "t-targetQA": "Energy Efficiency",
  "t-relatedQA": "Accuracy, Data Representativeness",
  "t-measuredimpact": "Reducing number of input features can result in a reduction of energy consumption while still maintaining accuracy.",
  "t-source": "Roberto Verdecchia, Luis Cruz, June Sallou, Michelle Lin, James Wickenden, and Estelle Hotellier. 2022. Data-Centric Green AI: An Exploratory Empirical Study. (2022). In 2022 International Conference on ICT for Sustainability (ICT4S). IEEE, 35â€“45",
  "t-source-doi": "https://doi.org/10.1002/widm.1507",
  "t-diagram": "reduce-number-of-data-features.png",
  "t-intentmeasure": "<Unavailable>",
  "t-countermeasure": "<Unavailable>"
}
